# .gitlab-ci.yml
# This file defines the CI/CD pipeline for your Python web application.

# Define the stages of the pipeline
stages:
  - lint                # Code quality and style checks
  - test                # Unit tests
  - integration_test    # Integration tests (e.g., database connectivity)
  - dependency_scan     # Check for vulnerabilities in dependencies
  - sast_scan           # Static Application Security Testing
  - secret_detection_scan # Scan for hardcoded secrets
  - build_docker        # Build Docker image
  - image_scan          # Scan Docker image for vulnerabilities
  - deploy_staging      # Placeholder for deploying to a staging environment
  - dast_scan           # Dynamic Application Security Testing

# Default settings for all jobs
default:
  # Cache pip dependencies to speed up subsequent builds
  cache:
    key: "$CI_COMMIT_REF_SLUG-pip" # Cache key based on branch/tag
    paths:
      - .cache/pip/  # Directory where pip caches downloads
      - venv/        # Cache the virtual environment if used
    policy: pull-push # Pull cache at the start, push at the end if job succeeds

variables:
  # Define Python version to use for consistency
  PYTHON_VERSION: "3.8"
  # Define the path to your application's requirements file
  # Assuming your project structure has requirements in DevSecOps/Task3/
  REQUIREMENTS_FILE: "DevSecOps/Task3/requirements.txt"
  # Define the path to your main application code
  APP_CODE_PATH: "DevSecOps/Task3/app/"
  # Define the path to your test files
  TEST_FILES_PATH: "DevSecOps/Task2/tests/"
  # Define the path to your Dockerfile and its build context
  DOCKERFILE_PATH: "DevSecOps/Task3/app/Dockerfile"
  DOCKER_CONTEXT_PATH: "DevSecOps/Task3/"
  # Define the image name for Docker, using GitLab's predefined variables
  DOCKER_IMAGE_NAME: "$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA"
  # Staging application URL - set this in GitLab CI/CD Variables or via your deploy script
  STAGING_APP_URL: "http://your-staging-app-url.com"

# --- LINTING STAGE ---
lint_code:
  stage: lint
  image: python:${PYTHON_VERSION}
  before_script:
    # Create a virtual environment and activate it
    - python -m venv venv
    - source venv/bin/activate
    # Configure pip to use the cache directory
    - pip config set global.cache-dir "$(pwd)/.cache/pip"
    # Install flake8
    - pip install flake8
  script:
    # Run flake8 on the application code path
    # Flake8 will exit with a non-zero code if issues are found
    - echo "Linting code with Flake8..."
    - flake8 ${APP_CODE_PATH}
  allow_failure: false # Fail the pipeline if linting errors are found

# --- UNIT TESTING STAGE ---
test_application:
  stage: test
  image: python:${PYTHON_VERSION}
  before_script:
    - python -m venv venv
    - source venv/bin/activate
    - pip config set global.cache-dir "$(pwd)/.cache/pip"
    # Install dependencies from the requirements file and pytest
    - pip install -r ${REQUIREMENTS_FILE}
    - pip install pytest
  script:
    # Run pytest on the test files path
    # Pytest will exit with a non-zero code if tests fail
    - echo "Running unit tests..."
    - python -m pytest ${TEST_FILES_PATH}test_app.py # Assuming your main unit tests are here
  allow_failure: false # Fail the pipeline if unit tests fail

# --- INTEGRATION TESTING STAGE ---
test_database_integration:
  stage: integration_test
  image: python:${PYTHON_VERSION}
  services:
    # Use a PostgreSQL service for database integration testing
    - name: postgres:13
      alias: test-postgres-db # Hostname to connect to this service
  variables:
    # Override SQLALCHEMY_DATABASE_URI for this job to point to the service container
    # This variable will be picked up by your app's config.py
    # Ensure your config.py uses os.environ.get('SQLALCHEMY_DATABASE_URI')
    SQLALCHEMY_DATABASE_URI: "postgresql://runner:@test-postgres-db:5432/testdb"
    # Variables for the PostgreSQL service
    POSTGRES_USER: "runner" # User for the test database
    POSTGRES_DB: "testdb"   # Name of the test database
    POSTGRES_HOST_AUTH_METHOD: "trust" # Allows connection without password from the runner
  before_script:
    - python -m venv venv
    - source venv/bin/activate
    - pip config set global.cache-dir "$(pwd)/.cache/pip"
    - pip install -r ${REQUIREMENTS_FILE}
    - pip install pytest psycopg2-binary # psycopg2-binary is needed for PostgreSQL
  script:
    - echo "Running database integration tests..."
    # Run the specific integration test file
    - python -m pytest ${TEST_FILES_PATH}test_integration_database.py
  allow_failure: false

# --- DEPENDENCY SCANNING STAGE ---
scan_dependencies:
  stage: dependency_scan
  image: python:${PYTHON_VERSION}
  before_script:
    - python -m venv venv
    - source venv/bin/activate
    - pip config set global.cache-dir "$(pwd)/.cache/pip"
    - pip install safety # Install safety for vulnerability scanning
  script:
    - echo "Scanning dependencies for vulnerabilities with Safety..."
    # Scan the requirements file. Safety exits with non-zero if vulnerabilities are found.
    - safety check -r ${REQUIREMENTS_FILE} --json --output safety-report.json || true
    # Check if safety found any vulnerabilities (exit code 1 from safety means vulnerabilities found)
    # We use `|| true` above to prevent immediate exit, then check the report.
    # A more robust way is to parse the JSON or use safety's exit codes directly if preferred.
    # For simplicity, we'll rely on safety's default exit code behavior for allow_failure.
    # If you want to fail explicitly based on severity, you might need a custom script.
    - safety check -r ${REQUIREMENTS_FILE}
  artifacts:
    paths:
      - safety-report.json
    when: always # Save the report even if the job fails
  allow_failure: false # Fail pipeline if vulnerabilities are found

# --- STATIC APPLICATION SECURITY TESTING (SAST) STAGE ---
static_analysis_bandit:
  stage: sast_scan
  image: python:${PYTHON_VERSION}
  before_script:
    - python -m venv venv
    - source venv/bin/activate
    - pip config set global.cache-dir "$(pwd)/.cache/pip"
    - pip install bandit # Install bandit for SAST
  script:
    - echo "Running SAST with Bandit..."
    # Run bandit on the application code path, outputting a JSON report.
    # -ll for medium severity, -ii for medium confidence. Adjust as needed.
    # Bandit exits with 1 if issues are found, 0 otherwise.
    - bandit -r ${APP_CODE_PATH} -f json -o bandit-report.json -ll -ii || if [ $? -eq 1 ]; then echo 'Bandit found issues!'; exit 1; else echo 'Bandit scan clear.'; exit 0; fi
  artifacts:
    paths:
      - bandit-report.json
    reports: # For GitLab SAST report integration
      sast: bandit-report.json
    when: always
  allow_failure: false # Fail pipeline if bandit finds issues based on the script logic

# --- SECRET DETECTION STAGE ---
scan_for_secrets:
  stage: secret_detection_scan
  image:
    name: zricethezav/gitleaks:latest # Official gitleaks Docker image
    entrypoint: [""] # Override default entrypoint
  script:
    - echo "Scanning for secrets with Gitleaks..."
    # Detect secrets in the entire repository.
    # Gitleaks exits with non-zero if secrets are found.
    - gitleaks detect --source . --report-path gitleaks-report.json --report-format json -v
  artifacts:
    paths:
      - gitleaks-report.json
    reports: # For GitLab Secret Detection report integration
      secret_detection: gitleaks-report.json
    when: always
  allow_failure: false # Fail pipeline if secrets are detected

# --- DOCKER BUILD STAGE ---
build_docker_image:
  stage: build_docker
  image: docker:latest # Use the official Docker image
  services:
    - docker:dind # Docker-in-Docker service is required to build Docker images
  before_script:
    # Login to GitLab Container Registry using predefined CI variables
    - echo "Logging in to GitLab Container Registry..."
    - docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" $CI_REGISTRY
  script:
    - echo "Building Docker image..."
    # Build the Docker image using the specified Dockerfile and context path
    - docker build -t ${DOCKER_IMAGE_NAME} -f ${DOCKERFILE_PATH} ${DOCKER_CONTEXT_PATH}
    - echo "Pushing Docker image to GitLab Container Registry..."
    # Push the built image to the GitLab Container Registry
    - docker push ${DOCKER_IMAGE_NAME}
  rules:
    # Only run this job on the default branch (e.g., main/master) or on tags
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH || $CI_COMMIT_TAG'

# --- DOCKER IMAGE SCANNING STAGE ---
scan_docker_image:
  stage: image_scan
  image: aquasec/trivy:latest # Use the official Trivy image
  variables:
    # Tell Trivy to fail the job if vulnerabilities of specified severities are found
    TRIVY_EXIT_CODE: "1"
    # Specify severities to scan for and fail on
    TRIVY_SEVERITY: "HIGH,CRITICAL"
    # Ensure Trivy knows it's running in CI
    CI: "true"
  script:
    - echo "Scanning Docker image ${DOCKER_IMAGE_NAME} for vulnerabilities with Trivy..."
    # Scan the Docker image (built in the previous stage)
    # Output format is set to gitlab for integrated vulnerability reports
    - trivy image --exit-code $TRIVY_EXIT_CODE --severity $TRIVY_SEVERITY --format gitlab --output trivy-gitlab-report.json ${DOCKER_IMAGE_NAME}
  artifacts:
    reports:
      container_scanning: trivy-gitlab-report.json # For GitLab's UI integration
    paths: # Also save the raw report if needed
      - trivy-gitlab-report.json
    when: always
  allow_failure: false # Fail pipeline if Trivy finds vulnerabilities matching criteria
  needs: ["build_docker_image"] # This job depends on the successful completion of build_docker_image
  rules:
    # Only run this job on the default branch or on tags (when build_docker_image runs)
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH || $CI_COMMIT_TAG'

# --- DEPLOY TO STAGING (Placeholder) ---
deploy_to_staging:
  stage: deploy_staging
  image: alpine # A small image for scripting
  script:
    - echo "Deploying application to staging environment: ${STAGING_APP_URL}"
    # Add your actual deployment scripts here.
    # This could involve kubectl, docker-compose up on a remote server, etc.
    # For example, if you use docker-compose.yml from DevSecOps/Task3/
    # You might scp it and then run 'docker-compose up -d'
    - echo "Deployment to ${STAGING_APP_URL} simulated."
  environment:
    name: staging
    url: ${STAGING_APP_URL} # Makes the URL accessible in GitLab UI
  rules:
    # Only run this job on the default branch
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
  # This job would typically depend on build_docker_image and image_scan
  needs: ["build_docker_image", "scan_docker_image"]


# --- DYNAMIC APPLICATION SECURITY TESTING (DAST) STAGE ---
dynamic_analysis_zap:
  stage: dast_scan
  # Using GitLab's managed DAST template is often the easiest way
  # It requires the DAST_WEBSITE variable to be set to your application's URL
  include:
    - template: DAST.gitlab-ci.yml
  variables:
    DAST_WEBSITE: ${STAGING_APP_URL} # URL of the deployed application
    DAST_BROWSER_SCAN: "false" # Set to true to enable AJAX spidering, can be slower
    DAST_FULL_SCAN_ENABLED: "true" # Perform a more thorough scan
  # If not using the template, you'd use an image like owasp/zap2docker-stable:
  # image: owasp/zap2docker-stable
  # script:
  #   - echo "Running DAST scan with OWASP ZAP on ${STAGING_APP_URL}..."
  #   - zap-baseline.py -t ${STAGING_APP_URL} -g gen-conf -J zap-report.json || echo "ZAP baseline scan completed."
  #   # For a full scan:
  #   # - zap-full-scan.py -t ${STAGING_APP_URL} -J zap-report.json || echo "ZAP full scan completed."
  # artifacts:
  #   paths:
  #     - zap-report.json
  #     - zap-report.html # If ZAP is configured to output HTML
  #   reports:
  #     dast: zap-report.json # For GitLab DAST report integration
  #   when: always
  allow_failure: true # DAST findings can be numerous; initially, you might not want to block the pipeline.
                      # Review findings and then set to false or use DAST_FAIL_ON_SEVERITY.
  needs: ["deploy_to_staging"] # This job depends on the successful deployment to staging
  rules:
    # Only run this job on the default branch after deployment
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
